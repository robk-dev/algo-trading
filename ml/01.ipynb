{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "history_points=50\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "# import dataset from alpha vantage as example csv\n",
    "# from util import csv_to_dataset, history_points, btc_csv_to_dataset\n",
    "\n",
    "# ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y, y_normaliser = csv_to_dataset('AAPL_daily.csv')\n",
    "# ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y, y_normaliser = btc_csv_to_dataset('BTC-USD_daily.csv')\n",
    "# ohlcv = open, high, low, close, volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-71d1f542b1b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ta'"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "import pandas as pd\n",
    "import ta\n",
    "\n",
    "# Load data\n",
    "# df = pd.read_csv('./data/BTC-USD_daily.csv', parse_dates=['time'])\n",
    "df = pd.read_csv('./data/BTC_USD-2012-01-01_to_2020-04-22.csv', parse_dates=['time'])\n",
    "\n",
    "df['date'] = pd.to_datetime(df['time'], unit='s')\n",
    "df.dropna()\n",
    "# df.reset_index()\n",
    "df.set_index('date', inplace=True)\n",
    "df.drop('time', axis=1, inplace=True)\n",
    "df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]] # make sure we only have ohlcv values\n",
    "\n",
    "\n",
    "split = 0.5 # remove first half of data, prior to 2016\n",
    "n = int(df.shape[0] * split)\n",
    "df = df[n:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(20,8))\n",
    "# sns.lineplot(x=df.index, y='open', data=df).set_title('BTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "resample_rate = '20H'\n",
    "data = df.resample(resample_rate).mean()\n",
    "sns.lineplot(x=data.index, y='open', data=data).set_title('BTC downsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,12))\n",
    "resample_rate = '1H'\n",
    "data = df.resample(resample_rate).mean()\n",
    "sns.lineplot(x=data.index, y='open', data=data).set_title('BTC downsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean na values\n",
    "data = ta.utils.dropna(data)\n",
    "print(df.columns)\n",
    "\n",
    "# Add all ta features filling nans values\n",
    "data = ta.add_all_ta_features(data, \"open\", \"high\", \"low\", \"close\", \"volume\", fillna=True)\n",
    "data.head()\n",
    "data.to_csv('./data/BTC-USD-1H-resampled-with-TA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.pct_change()\n",
    "# data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.lineplot(x=data.index, y='volatility_kch', data=data)\n",
    "sns.lineplot(x=data.index, y='volatility_bbm', data=data)\n",
    "sns.lineplot(x=data.index, y='trend_ichimoku_conv', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.dropna()\n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    # df = df.pct_change()\n",
    "    ohlcv_histories = df[df.columns[:5]] # data[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "    technical_indicators = df[df.columns[5:]] # the generated technical indicators\n",
    "\n",
    "    all_scaler = MinMaxScaler()\n",
    "    all_indicators = df.values\n",
    "    all_indicators = all_scaler.fit_transform(all_indicators)\n",
    "    all_indicators = np.array([all_indicators[i:i + history_points].copy() for i in range(len(all_indicators) - history_points)])\n",
    "\n",
    "    print(ohlcv_histories.shape)\n",
    "    print(technical_indicators.shape)\n",
    "    x_scaler = MinMaxScaler()\n",
    "    data_values = ohlcv_histories.values\n",
    "    data_normalised = x_scaler.fit_transform(data_values)\n",
    "\n",
    "\n",
    "\n",
    "    # using the last {history_points} open close high low volume data points, predict the next open value\n",
    "    ohlcv_normalised = np.array([data_normalised[i:i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    print(ohlcv_normalised.shape)\n",
    "\n",
    "\n",
    "\n",
    "    y_normalised = np.array([data_normalised[:, 0][i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    y_normalised = np.expand_dims(y_normalised, -1)\n",
    "    print(y_normalised.shape)\n",
    "\n",
    "    unscaled_y = np.array([data_values[:, 0][i + history_points].copy() for i in range(len(df) - history_points)])\n",
    "    unscaled_y = np.expand_dims(unscaled_y, -1)\n",
    "    print('unscaled_y', unscaled_y.shape)\n",
    "\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(unscaled_y)\n",
    "\n",
    "    print(technical_indicators.shape)\n",
    "    technical_indicators = technical_indicators[:len(ohlcv_normalised)]\n",
    "    print(technical_indicators.shape)\n",
    "\n",
    "    tech_ind_scaler = MinMaxScaler()\n",
    "    technical_indicators_normalised = tech_ind_scaler.fit_transform(technical_indicators)\n",
    "    print(technical_indicators_normalised.shape)\n",
    "    \n",
    "    \n",
    "    assert ohlcv_normalised.shape[0] == unscaled_y.shape[0] == technical_indicators_normalised.shape[0]\n",
    "    return ohlcv_normalised, technical_indicators_normalised, y_normalised, unscaled_y, y_scaler, all_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# def preprocess_pct_change(df):\n",
    "#    for col in df.columns:  # go through all of the columns\n",
    "#         if col != \"target\":  # normalize all ... except for the target itself!\n",
    "#             df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "#             df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "#             df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "\n",
    "#     df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y, y_normaliser, all_indicators = preprocess_df(data)\n",
    "# ohlcv = open, high, low, close, volume\n",
    "\n",
    "test_split = 0.9\n",
    "n = int(ohlcv_histories.shape[0] * test_split)\n",
    "\n",
    "ohlcv_train = ohlcv_histories[:n]\n",
    "tech_ind_train = technical_indicators[:n]\n",
    "y_train = next_day_open_values[:n]\n",
    "\n",
    "ohlcv_test = ohlcv_histories[n:]\n",
    "tech_ind_test = technical_indicators[n:]\n",
    "y_test = next_day_open_values[n:]\n",
    "\n",
    "unscaled_y_test = unscaled_y[n:]\n",
    "\n",
    "print(ohlcv_train.shape)\n",
    "print(ohlcv_test.shape)\n",
    "print(tech_ind_train.shape)\n",
    "print(tech_ind_test.shape)\n",
    "print(f\"ohlcv_test:{len(ohlcv_test)}\")\n",
    "print(f\"tech_ind_test:{len(tech_ind_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y, y_normaliser, all_indicators = preprocess_df(data)\n",
    "# # ohlcv = open, high, low, close, volume\n",
    "\n",
    "# test_split = 0.9\n",
    "# n = int(ohlcv_histories.shape[0] * test_split)\n",
    "\n",
    "# ohlcv_train = all_indicators[:n]\n",
    "# y_train = next_day_open_values[:n]\n",
    "\n",
    "# ohlcv_test = all_indicators[n:]\n",
    "# y_test = next_day_open_values[n:]\n",
    "\n",
    "# unscaled_y_test = unscaled_y[n:]\n",
    "\n",
    "# print(ohlcv_train.shape)\n",
    "# print(ohlcv_test.shape)\n",
    "# # print(tech_ind_train.shape)\n",
    "# # print(tech_ind_test.shape)\n",
    "# print(f\"ohlcv_test:{len(ohlcv_test)}\")\n",
    "# print(f\"tech_ind_test:{len(y_train)}\")\n",
    "# # model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # define two sets of inputs\n",
    "# lstm_input = Input(shape=(ohlcv_train.shape[1:]), name='lstm_input')\n",
    "# dense_input = Input(shape=(technical_indicators.shape[1],), name='tech_input')\n",
    "\n",
    "# # the first branch operates on the first input\n",
    "# x = LSTM(100, name='lstm_0', return_sequences=True)(lstm_input)\n",
    "# x = Dropout(0.2, name='lstm_dropout_0')(x)\n",
    "# x = BatchNormalization(name='batch_norm_0')(x)\n",
    "\n",
    "# x = LSTM(100, name='lstm_1')(x)\n",
    "# x = Dropout(0.1, name='lstm_dropout_1')(x)\n",
    "# x = BatchNormalization(name='batch_norm_1')(x)\n",
    "\n",
    "# # x = LSTM(128, name='lstm_2')(x)\n",
    "# # x = Dropout(0.15, name='lstm_dropout_2')(x)\n",
    "# # x = BatchNormalization(name='batch_norm_2')(x)\n",
    "\n",
    "# # model.add(LSTM(64))\n",
    "# # model.add(Dropout(0.2))\n",
    "# # model.add(BatchNormalization())\n",
    "# x = Dense(64, name='dense_output_0', activation='relu')(x)\n",
    "# # x = Dropout(0.2, name='dense_dropout_0')(x)\n",
    "\n",
    "# # x = Dense(1, activation=\"linear\", name='dense_out')(x)\n",
    "\n",
    "# lstm_branch = Model(inputs=lstm_input, outputs=x)\n",
    "\n",
    "# # the second branch opreates on the second input\n",
    "# y = Dense(100, name='tech_dense_0')(dense_input)\n",
    "# y = Activation(\"relu\", name='tech_relu_0')(y)\n",
    "# y = Dropout(0.1, name='tech_dropout_0')(y)\n",
    "\n",
    "# y = Dense(100, name='tech_dense_1')(dense_input)\n",
    "# y = Activation(\"relu\", name='tech_relu_1')(y)\n",
    "# # y = Dropout(0.2, name='tech_dropout_1')(y)\n",
    "# technical_indicators_branch = Model(inputs=dense_input, outputs=y)\n",
    "\n",
    "# # combine the output of the two branches\n",
    "# combined = concatenate([lstm_branch.output, technical_indicators_branch.output], name='concatenate')\n",
    "\n",
    "# z = Dense(64, activation=\"sigmoid\", name='dense_pooling')(combined)\n",
    "# z = Dense(1, activation=\"linear\", name='dense_out')(z)\n",
    "\n",
    "# # our model will accept the inputs of the two branches and\n",
    "# # then output a single value\n",
    "# # model = Model(inputs=lstm_branch.input, outputs=z)\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# name = f\"seq_len[{history_points}]-15m-t{int(time.time())}\"\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "# filepath = \"models/acc-{val_accuracy:.3f}-{epoch:02d}.h5\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') # saves only the best ones\n",
    "\n",
    "\n",
    "# model.fit(x=[ohlcv_train, tech_ind_train],  y=y_train, batch_size=32, epochs=50, shuffle=True, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64,input_shape=(ohlcv_train.shape[1:]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(LSTM(64,  return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(LSTM(64))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     ohlcv_train, y_train,\n",
    "#     batch_size=32,\n",
    "#     epochs=50,\n",
    "#     validation_data=(ohlcv_test, y_test),\n",
    "#     callbacks=[[tensorboard]]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# model architecture\n",
    "\n",
    "# define two sets of inputs\n",
    "lstm_input = Input(shape=(history_points, 5), name='lstm_input')\n",
    "dense_input = Input(shape=(technical_indicators.shape[1],), name='tech_input')\n",
    "\n",
    "# the first branch operates on the first input\n",
    "x = LSTM(256, name='lstm_0', return_sequences=True)(lstm_input)\n",
    "x = Dropout(0.2, name='lstm_dropout_0')(x)\n",
    "x = BatchNormalization(name='batch_norm_0')(x)\n",
    "\n",
    "x = LSTM(256, name='lstm_1')(x)\n",
    "x = Dropout(0.1, name='lstm_dropout_1')(x)\n",
    "x = BatchNormalization(name='batch_norm_1')(x)\n",
    "\n",
    "# model.add(LSTM(64))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "x = Dense(128, name='dense_output_0', activation='relu')(x)\n",
    "x = Dropout(0.2, name='dense_dropout_0')(x)\n",
    "\n",
    "lstm_branch = Model(inputs=lstm_input, outputs=x)\n",
    "\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(256, name='tech_dense_0')(dense_input)\n",
    "y = Activation(\"relu\", name='tech_relu_0')(y)\n",
    "y = Dropout(0.1, name='tech_dropout_0')(y)\n",
    "\n",
    "y = Dense(256, name='tech_dense_1')(dense_input)\n",
    "y = Activation(\"relu\", name='tech_relu_1')(y)\n",
    "y = Dropout(0.2, name='tech_dropout_1')(y)\n",
    "technical_indicators_branch = Model(inputs=dense_input, outputs=y)\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([lstm_branch.output, technical_indicators_branch.output], name='concatenate')\n",
    "\n",
    "z = Dense(128, activation=\"sigmoid\", name='dense_pooling')(combined)\n",
    "z = Dense(1, activation=\"linear\", name='dense_out')(z)\n",
    "\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[lstm_branch.input, technical_indicators_branch.input], outputs=z)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "name = f\"seq_len[{history_points}]-15m-t{int(time.time())}\"\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "filepath = \"models/acc-{val_accuracy:.3f}-{epoch:02d}.h5\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') # saves only the best ones\n",
    "\n",
    "\n",
    "model.fit(x=[ohlcv_train, tech_ind_train], y=y_train, batch_size=32, epochs=50, shuffle=True, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# evaluation\n",
    "print(len(tech_ind_test))\n",
    "y_test_predicted = model.predict([ohlcv_test, tech_ind_test])\n",
    "y_test_predicted = y_normaliser.inverse_transform(y_test_predicted)\n",
    "y_predicted = model.predict([ohlcv_histories, technical_indicators])\n",
    "y_predicted = y_normaliser.inverse_transform(y_predicted)\n",
    "assert unscaled_y_test.shape == y_test_predicted.shape\n",
    "real_mse = np.mean(np.square(unscaled_y_test - y_test_predicted))\n",
    "scaled_mse = real_mse / (np.max(unscaled_y_test) - np.min(unscaled_y_test)) * 100\n",
    "print(scaled_mse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "\n",
    "start = 0\n",
    "end = -1\n",
    "\n",
    "real = plt.plot(unscaled_y_test[start:end], label='real')\n",
    "pred = plt.plot(y_test_predicted[start:end], label='predicted')\n",
    "\n",
    "# real = plt.plot(unscaled_y[start:end], label='real')\n",
    "# pred = plt.plot(y_predicted[start:end], label='predicted')\n",
    "\n",
    "plt.legend(['Real', 'Predicted'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import time\n",
    "model.save(f'./models/ohlcv-ind-{time.time()}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "real = plt.plot(unscaled_y[start:end], label='real')\n",
    "pred = plt.plot(y_predicted[start:end], label='predicted')\n",
    "plt.legend(['Real', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_price_tomorrow = np.squeeze(y_normaliser.inverse_transform(model.predict([ohlcv_histories, technical_indicators]))) \n",
    "buys = []\n",
    "sells = []\n",
    "thresh = 7.77\n",
    "tr_perc = 1.11\n",
    "print(predicted_price_tomorrow)\n",
    "start = 0\n",
    "end = -1\n",
    "\n",
    "x = -1\n",
    "\n",
    "# for prediction in predicted_price_tomorrow:\n",
    "\n",
    "# for ohlcv, tech_ind in zip(ohlcv_test[start: end], tech_ind_test[start: end]):\n",
    "for i, ohlcv in enumerate(ohlcv_histories[start:end-6]):\n",
    "    normalised_price_today = ohlcv[-1][0]\n",
    "    normalised_price_today = np.array([[normalised_price_today]])\n",
    "    price_today = y_normaliser.inverse_transform(normalised_price_today)[0][0]\n",
    "    price_tomorrow = predicted_price_tomorrow[i+6]\n",
    "    # delta = price_tomorrow - price_today\n",
    "    delta = price_tomorrow / price_today\n",
    "   # print( price_tomorrow, price_today)\n",
    "\n",
    "    if  (price_tomorrow / price_today) > tr_perc:\n",
    "        buys.append((x, price_today))\n",
    "    elif  (price_today / price_tomorrow) > tr_perc:\n",
    "        sells.append((x, price_today))\n",
    "    \n",
    "    # if  price_tomorrow > (price_today*thresh):\n",
    "    #     buys.append((x, price_today))\n",
    "    # elif price_tomorrow < (price_today*thresh):\n",
    "    #     sells.append((x, price_today))\n",
    "\n",
    "    # if delta > thresh:\n",
    "    #     buys.append((x, price_today))\n",
    "    # elif delta < -thresh:\n",
    "    #     sells.append((x, price_today))\n",
    "    x += 1\n",
    "print(f\"buys: {len(buys)}\")\n",
    "print(f\"sells: {len(sells)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_earnings(buys_, sells_):\n",
    "    purchase_amt = 1000\n",
    "    stock = 0\n",
    "    balance = 0\n",
    "    while len(buys_) > 0 and len(sells_) > 0:\n",
    "        if buys_[0][0] < sells_[0][0]:\n",
    "            # time to buy $10 worth of stock\n",
    "            balance -= purchase_amt\n",
    "            stock += purchase_amt / buys_[0][1]\n",
    "            buys_.pop(0)\n",
    "        else:\n",
    "            # time to sell all of our stock\n",
    "            balance += stock * sells_[0][1]\n",
    "            stock = 0\n",
    "            sells_.pop(0)\n",
    "    print(f\"earnings: ${balance}\")\n",
    "\n",
    "\n",
    "# we create new lists so we dont modify the original\n",
    "compute_earnings([b for b in buys], [s for s in sells])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "\n",
    "# real = plt.plot(unscaled_y_test[start:end], label='real')\n",
    "# pred = plt.plot(y_test_predicted[start:end], label='predicted')\n",
    "\n",
    "if len(buys) > 0:\n",
    "    plt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c='#00ff00', s=50)\n",
    "if len(sells) > 0:\n",
    "    plt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c='#ff0000', s=50)\n",
    "\n",
    "print(unscaled_y)\n",
    "real = plt.plot(unscaled_y[start:end], label='real')\n",
    "pred = plt.plot(y_predicted[start:end], label='predicted')\n",
    "\n",
    "plt.legend(['Real', 'Predicted', 'Buy', 'Sell'])\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.show()\n",
    "model.save('./models/huge-lstm-dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "\n",
    "# real = plt.plot(unscaled_y_test[start:end], label='real')\n",
    "# pred = plt.plot(y_test_predicted[start:end], label='predicted')\n",
    "\n",
    "if len(buys) > 0:\n",
    "    plt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c='#00ff00', s=50)\n",
    "if len(sells) > 0:\n",
    "    plt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c='#ff0000', s=50)\n",
    "\n",
    "print(unscaled_y)\n",
    "real = plt.plot(unscaled_y[int(len(unscaled_y)*0.75):end], label='real')\n",
    "pred = plt.plot(y_predicted[int(len(unscaled_y)*0.75):end], label='predicted')\n",
    "\n",
    "plt.legend(['Real', 'Predicted', 'Buy', 'Sell'])\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.show()\n",
    "model.save('./models/huge-lstm-dense.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}